{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed634a9-92e9-4276-85eb-731cacc82d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test su Digits Dataset - XGBoost vs Random Forest\n",
      "Random State | Random Forest (100 trees) | XGBoost\n",
      "------------------------------------------------------------\n",
      "1            | 0.99                 | 0.98\n",
      "5            | 0.96                 | 0.94\n",
      "7            | 0.97                 | 0.96\n",
      "10           | 0.96                 | 0.96\n",
      "15           | 0.96                 | 0.95\n",
      "21           | 0.99                 | 0.97\n",
      "42           | 0.98                 | 0.96\n",
      "55           | 0.99                 | 0.98\n",
      "77           | 0.97                 | 0.98\n",
      "99           | 0.99                 | 0.98\n",
      "\n",
      "Media Accuracy Random Forest (100 trees): 0.976\n",
      "Media Accuracy XGBoost: 0.964\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carichiamo il dataset Digits\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Lista di random_state da testare\n",
    "random_states = [1, 5, 7, 10, 15, 21, 42, 55, 77, 99]\n",
    "\n",
    "print(\"\\nTest su Digits Dataset - XGBoost vs Random Forest\")\n",
    "print(\"Random State | Random Forest (100 trees) | XGBoost\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rf_accuracies = []\n",
    "xgb_accuracies = []\n",
    "\n",
    "for rs in random_states:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=rs)\n",
    "\n",
    "    # Random Forest con 100 alberi\n",
    "    modello_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=rs)\n",
    "    modello_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = modello_rf.predict(X_test)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    rf_accuracies.append(accuracy_rf)\n",
    "\n",
    "    # XGBoost con 100 estimatori\n",
    "    modello_xgb = xgb.XGBClassifier(n_estimators=100, max_depth=10, eval_metric=\"mlogloss\")\n",
    "    modello_xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = modello_xgb.predict(X_test)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    xgb_accuracies.append(accuracy_xgb)\n",
    "\n",
    "    print(f\"{rs:<12} | {accuracy_rf:.2f}                 | {accuracy_xgb:.2f}\")\n",
    "\n",
    "rf_mean = np.mean(rf_accuracies)\n",
    "xgb_mean = np.mean(xgb_accuracies)\n",
    "\n",
    "print(\"\\nMedia Accuracy Random Forest (100 trees):\", round(rf_mean, 3))\n",
    "print(\"Media Accuracy XGBoost:\", round(xgb_mean, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1bd750-b204-4c66-a5d0-33d7d478a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test su Digits Dataset - XGBoost vs Random Forest\n",
      "Random State | Random Forest (100 trees) | XGBoost\n",
      "------------------------------------------------------------\n",
      "1            | 0.99                 | 0.98\n",
      "5            | 0.96                 | 0.97\n",
      "7            | 0.97                 | 0.97\n",
      "10           | 0.96                 | 0.96\n",
      "15           | 0.96                 | 0.98\n",
      "21           | 0.99                 | 0.99\n",
      "42           | 0.98                 | 0.98\n",
      "55           | 0.99                 | 0.99\n",
      "77           | 0.97                 | 0.98\n",
      "99           | 0.99                 | 0.98\n",
      "\n",
      "Media Accuracy Random Forest (100 trees): 0.976\n",
      "Media Accuracy XGBoost: 0.978\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carichiamo il dataset Digits\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Lista di random_state da testare\n",
    "random_states = [1, 5, 7, 10, 15, 21, 42, 55, 77, 99]\n",
    "\n",
    "print(\"\\nTest su Digits Dataset - XGBoost vs Random Forest\")\n",
    "print(\"Random State | Random Forest (100 trees) | XGBoost\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rf_accuracies = []\n",
    "xgb_accuracies = []\n",
    "\n",
    "for rs in random_states:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=rs)\n",
    "\n",
    "    # Random Forest con 100 alberi\n",
    "    modello_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=rs)\n",
    "    modello_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = modello_rf.predict(X_test)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    rf_accuracies.append(accuracy_rf)\n",
    "\n",
    "    # XGBoost con 100 estimatori\n",
    "    modello_xgb = xgb.XGBClassifier(n_estimators=300, learning_rate=0.18, max_depth=12, subsample=0.5, colsample_bytree=0.5, eval_metric=\"mlogloss\")\n",
    "    modello_xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = modello_xgb.predict(X_test)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    xgb_accuracies.append(accuracy_xgb)\n",
    "\n",
    "    print(f\"{rs:<12} | {accuracy_rf:.2f}                 | {accuracy_xgb:.2f}\")\n",
    "\n",
    "rf_mean = np.mean(rf_accuracies)\n",
    "xgb_mean = np.mean(xgb_accuracies)\n",
    "\n",
    "print(\"\\nMedia Accuracy Random Forest (100 trees):\", round(rf_mean, 3))\n",
    "print(\"Media Accuracy XGBoost:\", round(xgb_mean, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c376058-1a5a-4817-865c-f1138d9b3807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test su Digits Dataset - XGBoost vs Random Forest\n",
      "Random State | Random Forest (100 trees) | XGBoost\n",
      "------------------------------------------------------------\n",
      "1            | 0.99                 | 0.99\n",
      "5            | 0.96                 | 0.96\n",
      "7            | 0.97                 | 0.97\n",
      "10           | 0.96                 | 0.97\n",
      "15           | 0.96                 | 0.98\n",
      "21           | 0.99                 | 0.98\n",
      "42           | 0.98                 | 0.98\n",
      "55           | 0.99                 | 0.99\n",
      "77           | 0.97                 | 0.98\n",
      "99           | 0.99                 | 0.99\n",
      "\n",
      "Media Accuracy Random Forest (100 trees): 0.976\n",
      "Media Accuracy XGBoost: 0.979\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carichiamo il dataset Digits\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Lista di random_state da testare\n",
    "random_states = [1, 5, 7, 10, 15, 21, 42, 55, 77, 99]\n",
    "\n",
    "print(\"\\nTest su Digits Dataset - XGBoost vs Random Forest\")\n",
    "print(\"Random State | Random Forest (100 trees) | XGBoost\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rf_accuracies = []\n",
    "xgb_accuracies = []\n",
    "\n",
    "for rs in random_states:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=rs)\n",
    "\n",
    "    # Random Forest con 100 alberi\n",
    "    modello_rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=rs)\n",
    "    modello_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = modello_rf.predict(X_test)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    rf_accuracies.append(accuracy_rf)\n",
    "\n",
    "    # XGBoost con 100 estimatori\n",
    "    modello_xgb = xgb.XGBClassifier(n_estimators=300, learning_rate=0.18, max_depth=12, subsample=0.5, colsample_bytree=0.5, gamma=0, reg_alpha=0.05, reg_lambda=1.0, eval_metric=\"mlogloss\")\n",
    "    modello_xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = modello_xgb.predict(X_test)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    xgb_accuracies.append(accuracy_xgb)\n",
    "\n",
    "    print(f\"{rs:<12} | {accuracy_rf:.2f}                 | {accuracy_xgb:.2f}\")\n",
    "\n",
    "rf_mean = np.mean(rf_accuracies)\n",
    "xgb_mean = np.mean(xgb_accuracies)\n",
    "\n",
    "print(\"\\nMedia Accuracy Random Forest (100 trees):\", round(rf_mean, 3))\n",
    "print(\"Media Accuracy XGBoost:\", round(xgb_mean, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0ac9a66-c3bb-40c5-86c6-61d8ff83849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versione non ottimizzata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab7f5450-699c-48b0-86de-a9c9ab498933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test su Digits Dataset - XGBoost Versione Iniziale\n",
      "Random State | XGBoost (Default)\n",
      "----------------------------------------\n",
      "1            | 0.967\n",
      "5            | 0.944\n",
      "7            | 0.956\n",
      "10           | 0.961\n",
      "15           | 0.950\n",
      "21           | 0.978\n",
      "42           | 0.967\n",
      "55           | 0.972\n",
      "77           | 0.978\n",
      "99           | 0.972\n",
      "\n",
      "Media Accuracy XGBoost (Versione Iniziale): 0.964\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carichiamo il dataset Digits\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Lista di random_state da testare\n",
    "random_states = [1, 5, 7, 10, 15, 21, 42, 55, 77, 99]\n",
    "\n",
    "print(\"\\nTest su Digits Dataset - XGBoost Versione Iniziale\")\n",
    "print(\"Random State | XGBoost (Default)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "xgb_accuracies_default = []\n",
    "\n",
    "for rs in random_states:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=rs)\n",
    "\n",
    "    # XGBoost con impostazioni di default\n",
    "    modello_xgb = xgb.XGBClassifier(n_estimators=100, eval_metric=\"mlogloss\")  # Impostazioni predefinite\n",
    "    modello_xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = modello_xgb.predict(X_test)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    xgb_accuracies_default.append(accuracy_xgb)\n",
    "\n",
    "    print(f\"{rs:<12} | {accuracy_xgb:.3f}\")\n",
    "\n",
    "# Calcoliamo la media dell'accuracy iniziale\n",
    "xgb_mean_default = np.mean(xgb_accuracies_default)\n",
    "print(\"\\nMedia Accuracy XGBoost (Versione Iniziale):\", round(xgb_mean_default, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80ae45-31aa-4193-a5a2-9eb6c616d3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
